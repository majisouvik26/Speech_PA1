**References & Datasets used**

1. **K. Dhawan, D. Rekesh, and B. Ginsburg.**  
   “Unified Model for Code-Switching Speech Recognition and Language Identification Based on Concatenated Tokenizer.”  
   *Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching*, 2023.

2. **H. Wang, X. Wan, N. Zheng, K. Liu, H. Zhou, G. Li, and L. Xie.**  
   “CAMEL: Cross-Attention Enhanced Mixture-of-Experts and Language Bias for Code-Switching Speech Recognition.”  
   *arXiv preprint arXiv:2412.12760*, 2025.

3. **V. Panayotov, G. Chen, D. Povey, and S. Khudanpur.**  
   “Librispeech: An ASR corpus based on public domain audio books.”  
   *Proceedings of ICASSP*, 2015.

4. **M. Deuchar, P. Davies, J. R. Herring, M. C. Parafita Couto, and D. Carter.**  
   “Building bilingual corpora: The Miami Bangor Corpus.”  
   In *Advances in the Study of Bilingualism*, 2014.

5. **E. Y. Ugan, N. Pham, and A. Waibel.**  
   “DECM: Evaluating Bilingual ASR Performance on a Code-switching/Mixing Benchmark.”  
   *Proceedings of LREC-COLING*, 2024.

6. **F. Weng, H. Bratt, L. Neumeyer, and A. Stolcke.**  
   “A study of multilingual speech recognition.”  
   *Proceedings of the European Conference on Speech Communication and Technology (EUROSPEECH)*, 1997.

7. **A. Waibel, H. Soltau, T. Schultz, T. Schaaf, and F. Metze.**  
   “Multilingual speech recognition.”  
   In *Verbmobil: Foundations of Speech-to-Speech Translation*, Springer, 2000.

8. **A. Ali, S. A. Chowdhury, A. Hussein, and Y. Hifny.**  
   “Arabic code-switching speech recognition using monolingual data.”  
   *Proceedings of Interspeech*, 2021.

9. **S. Sitaram, K. R. Chandu, S. K. Rallabandi, and A. W. Black.**  
   “A survey of code-switched speech and language processing.”  
   *arXiv preprint arXiv:1904.00784*, 2019.

10. **A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber.**  
    “Connectionist temporal classification: Labeling unsegmented sequence data with recurrent neural networks.”  
    *Proceedings of ICML*, 2006.

11. **A. Graves.**  
    “Sequence transduction with recurrent neural networks.”  
    *arXiv preprint arXiv:1211.3711*, 2013.

12. **A. Radford, J. Wook Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.**  
    “Robust speech recognition via large-scale weak supervision.”  
    *arXiv preprint arXiv:2212.04356*, 2022.

13. **V. Pratap, A. Tjandra, B. Shi, P. Tomasello, A. Babu, et al.**  
    “Scaling speech technology to 1,000+ languages.”  
    *arXiv preprint arXiv:2305.13516*, 2023.

14. **H. Seki, T. Hori, S. Watanabe, J. R. Le Roux, and J. R. Hershey.**  
    “End-to-end multilingual multi-speaker speech recognition.”  
    *Proceedings of Interspeech*, 2019.

15. **G. I. Winata, A. Madotto, C.-S. Wu, and P. Fung.**  
    “Code-switched language models using neural-based synthetic data from parallel sentences.”  
    *arXiv preprint arXiv:1909.08582*, 2019.

16. **D. Gupta, A. Ekbal, and P. Bhattacharyya.**  
    “A semi-supervised approach to generate the code-mixed text using pre-trained encoder and transfer learning.”  
    *Findings of the Association for Computational Linguistics (EMNLP)*, 2020.

17. **I. Tarunesh, S. Kumar, and P. Jyothi.**  
    “From machine translation to code-switching: Generating high-quality code-switched text.”  
    *arXiv preprint arXiv:2107.06483*, 2021.

18. **H. Seki, S. Watanabe, T. Hori, J. Le Roux, and J. R. Hershey.**  
    “An end-to-end language-tracking speech recognizer for mixed-language speech.”  
    *Proceedings of ICASSP*, 2018.

19. **O. Weller, M. Sperber, T. Pires, H. Setiawan, C. Gollan, D. Telaar, and M. Paulik.**  
    “End-to-end speech translation for code-switched speech.”  
    *Proceedings of ACL*, 2022.

20. **NVIDIA NeMo Toolkit.**  
    “NeMo: Speech and Language Processing Toolkit.”  
    <https://github.com/NVIDIA/NeMo>, 2023.

21. **A. Conneau et al.**  
    “FLEURS: Few-shot learning evaluation of universal representations of speech.”  
    *Proceedings of SLT*, 2023.

22. **ULCA.**  
    “ULCA Speech Dataset: A multilingual corpus for ASR research.”  
    Govt. of India, Bhashini Initiative, 2022. Available: <https://ulca.in>

23. **K. Diwan, R. Kumar, A. Singh, et al.**  
    “Multilingual and code-switching ASR challenges for low-resource Indian languages: The MUCS 2021 benchmark.”  
    *Proceedings of Interspeech*, 2021.

24. **N. Wang, L. Wu, J. Zhang, et al.**  
    “VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning, and interpretation.”  
    *Proceedings of NeurIPS*, 2021.

25. **C. Cieri, D. Miller, and K. Walker.**  
    “The Fisher corpus: A resource for the next generations of speech-to-text.”  
    *Proceedings of LREC*, 2004.

26. **A. Ardila, M. Branson, K. Davis, et al.**  
    “Common Voice: A massively-multilingual speech corpus.”  
    *Proceedings of LREC*, 2020.

---

